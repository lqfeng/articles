自然语言理解中的联合学习

## 1.联合学习

在前文中，我们通过两个模型分别处理了槽位提取和意图识别，然后通过**流水线的方式（Pipelined Method）**，将两个结果串联在一起，完成了整个流程，在这个过程中，我们可以发现，两个模型的输入是完全一致的，即都是用户输入的query，同时，两个任务也有非常强的联系，那么我们在这里会问，我们这两个步骤既然输入一样，那么能否将其合二为一呢，即做到一个输入，多个输出，让我们的模型能够一步到位，直接输出我们所有步骤最终所需要的结果，进行**联合学习（Joint learning）**。

答案是肯定的，在本文中，我们将会介绍一下怎样将前两批文章中介绍的的流水线模型整合为一个**联合模型（Joint model）**。



![image-20181020171027705](images/image-20181020171027705.png)





## 2.联合学习的优势

1.一个显而易见的就是整个流程中的模块减少了，模块的减少意味着上下游联调的时间，跨模块调用，以及信息传递的步骤会有所减少，而这对于一个多模块的系统来说，开发的工作量，系统的耗时，可以在整体上降低。

2.联合学习省去了在每一个独立学习任务执行之前所做的数据标注工作，为样本做标注的代价是昂贵的、易出错的。后面模型的对于特征的处理以及标注等工作可以省略许多，让我们把更多的实际放在整体的模型优化上。

3.对于流水线模型，每个模型都是在自己的任务上求得一个最优解，然后将其串联起来，但是各个模型之间的优化目标是分裂的，每个独立任务的最优解在整体的目标上不一定是全局最优的。

这些看似断开连接的任务之间是存在一些信息重叠的，因此，联合模型可以访问比仅针对该特定任务训练的模型更多的关于每个单独任务的信息。比如如果槽位中含有地点信息，那么会对导航这个意图有正向的辅助，而流水线的方式没有办法利用这里更隐层的信息，相比流水线模型，联合学习具有协同增效的优势，有更大可能获得全局最优解。

4.节约计算资源，通过端到端模型，可以复用部分的网络结构，所以在模型训练的过程中复用的网络层可以经过一次训练而同时对多个任务生效，同时在整体任务上达到最优化的参数，同时在上线应用后，也可以比流水线模式节约线上的机器资源。

## 3.联合模型的结构

![image-20181020190354844](images/image-20181020190354844.png)

## 4.联合模型的学习

从上图的结构中看，联合模型与之前流水线的模型差别在于，流水线模型只有一个输出，而联合模型同时输出了两种结果，两个任务同时共享BI-LSTM层及以前层次的参数。这样可以共享二者的隐藏层的一些信息，互相协同影响对方的识别能力。

在这里，槽位提取任务和意图检测任务，分别有一个损失函数loss1和loss2，那么我们在训练的时候，只需要将二者的损失函数加在一起，然后训练最终的加和loss=loss1+loss2就可以了。

这是一种简单有效的手段，最终经过多次的迭代，模型最终会收敛到二者在整个网络上的最小值，让整个模型达到最优化。





## 5.结语

最后然我们一起飞
