## 1.摘要

在前文中，我们通过两个模型分别处理了槽位提取和意图识别任务，然后通过**流水线的方式（Pipeline）**，将两个任务串联在一起，完成了获取槽位和意图流程，在这个过程中，我们可以发现，两个模型的输入信息是一致的，同时，两个任务也有一定的的联系。既然如此，那么能否将其合二为一呢？也就是做到一个输入，多个输出，在同一个网络中训练，让我们的模型能够一步到位，直接输出我们所有需要的结果。

答案是肯定的，在本文中，我们将会介绍一下怎样将前两篇文中介绍的各自独立的模型进行多任务**联合学习（Joint learning）**。整合为一个统一的**联合模型（Joint model）**。

![image-20181020171027705](images/image-20181020171027705.png)

## 2.多任务联合学习

多任务联合学习指的是：我们有多个相关的预测任务（可以相互依赖，也可以不依赖），并利用其中一种任务中所蕴含的信息来提升其它任务的准确率。

因为各个任务之间有有一定的相关性，这种相关性意味着当我们学会解决一个任务的时候，它也会为另一个任务提供隐含信息，而这种隐含信息可以改善另一个任务的泛化能力。

## 3.解决方法

在深度学习的框架下，解决思路是对于不同的任务使用不同的网络，但是这些网络之间共享部分的结构与参数，通过这种方式，模型的核心预测组件（共享结构）将受到所有任务的影响，而且一种任务的训练数据可能有助于改善其它任务的预测。在这个共享的结构之上，网络含有多个输出层，对于每个任务都有有一个各自的专用的预测结构，而且最终预测结构的权重矩阵和偏置项为各个任务所专用。

该网络中的大部分参数是在不同的任务之间共享，因此，其中一个任务中所学到的有用信息能够帮助其他任务进行歧义消解。

在这样一个多输出的神经网络中，我们对每个任务的输出均计算一个单独的损失，并将这多个任务的损失求和从而得到整体损失，进而根据该损失进行误差梯度的计算。

## 4.联合模型的结构

我们根据之前两篇文中介绍的两个任务，槽位提取和意图识别，作为参考，构建一个联合模型，并做结构图如下。

从下图的结构中看，联合模型与之前流水线的模型差别在于，流水线模型中是两个串行的模型，每个模型只有一个输出，而联合模型是在一个模型中同时含有两个输出，两个任务同时共享BI-LSTM及之前层次的网络结构及参数。这样二者都可以在共享层获取对方的隐含信息，然后利用这些隐含信息来提升自己的泛化能力。

在这里，槽位提取任务和意图检测任务，分别有一个损失，在训练的时候，我们将二个损失加在一起进行求和，然后对这个整体损失进行梯度计算。

![image-20181020190354844](images/image-20181020190354844.png)

## 5.联合学习的优势

1. 一个显而易见的优点就是整个流程中的模块减少了，模块的减少意味着上下游的联调，跨模块调用，以及信息传递的步骤会有所减少，而这对于一个多模块的系统来说，开发的工作量，系统的耗时，可以在整体上降低。

2. 对于流水线模型，每个模型都是在自己的任务上求得一个最优解，然后将其串联起来，但是各个模型之间的优化目标是分裂的，每个独立任务的最优解在整体的目标上不是全局最优的。通过联合学习，将二者的损失放在一起计算，从而可以在整体的任务上取得全局的最优。

   另外这些看似不相关的任务之间是存在一些信息重叠的，联合模型可以访问比仅针对该特定任务训练的模型更多的关于每个单独任务的信息。比如通过槽位中的信息，可以对意图识别任务有正向的帮助，而流水线的方式没有办法利用这里更隐层的信息，相比流水线模型，联合学习具有协同增效的优势，可以比单任务学习获得更好的泛化效果。

3. 节约资源，在联合模型中，会共享部分的网络结构，所以在模型训练的过程中，共享的网络层经过一次训练就会对多个任务同时生效，节约训练机器的资源。另外在应用上线后，联合模型也可以比流水线模型节约线上的机器资源。

## 6.参考资料

1.[多任务学习概述论文：从定义和方法到应用和原理分析](https://www.jiqizhixin.com/articles/nsr-jan-2018-yu-zhang-qiang-yang)

2.[多任务学习-Multitask Learning概述](https://zhuanlan.zhihu.com/p/27421983)

3.[一箭N雕：多任务深度学习实战](https://zhuanlan.zhihu.com/p/22190532)

4.[基于神经网络的实体识别和关系抽取联合学习](https://cloud.tencent.com/developer/article/1050023)