基于BI-LSTM-CRF的NLU slot filling实战



# 概述

​	在语音助手的这一类产品中，能够准确理解用户的输入信息（自然语言理解（NLU：Natural Language Understanding）），是非常重要的，通过对于用户输入信息的组织与抽取，将其转换为程序能够正确是别的结构化信息，才能给与用户准确的反馈，而在这个过程当中，意图检测（intent detection）和槽位填充（slot filling），是其中的基础的工作。

​	**意图检测（intent detection）**：意图检测的目的，是判断用户的输入是想要做什么。比如，当用户说：“今天天气怎么样”，这里的意图就是查询天气。“我要去万达广场”，这就是一个导航的意图。

​	**槽位填充（slot filling）**：槽位填充，就是将用户输入的信息中，根据我们既定的一些结构化字段，将其提取出来，这样可以对后续的处理流程更加准确的给与反馈。还是上面的例子，“今天天气怎么样”，可以提取出一个时间的slot，这里就是“今天”，“我要去万达广场”里面的含有一个地点的slot, 这里就是“万达广场”。slot与具体的任务有密切的关系。

​	这样，我们就可以根据提取的意图和槽位，来查询我们云端的服务，然后云端反馈给用户所需的信息，这里的intent相当于一个云端接口，而slot就是这个接口对应的参数，比如“今天天气怎么样”，就会向查询天气的接口发送请求，参数中的日期是今天的时间，最后该接口就返回今天的天气信息给到用户。当然，具体到真实的语音助手的交互流程，会比这里更复杂，考虑的细节也会更多，这里只是简单的说一下方便理解。

​	本次，我会主要介绍一下我在**槽位填充（slot filling）**这里的一些工作。

​	另外在实际的应用中，通过后面介绍技术，提取了POI，用户偏好，路况信息等十几个类别的slot信息， 下述为方便理解，仅使用POI来做例子。

-------

​	**命名实体识别（英语：Named Entity Recognition，简称NER）**，又称作专名识别，是指识别文本中具有特定意义的实体，是自然语言处理(NLP)领域的基础任务之一。传统的NER任务主要包括识别人名、地名、机构名、专有名词等，以及时间、数量、货币、比例数值等文字。

​	槽位填充（slot filling）可以认为是对传统NER任务的扩展，是更加广义上的NER，可以对具体的域（domain：intent之上的类别，如音乐域有播放音乐，暂停音乐等不同的intent）里面定义具体的类别，比如导航域中的POI，音乐域中的歌手以及歌曲，专辑等等，都是对于特定域中的的实体，所以我们在这里slot filling所应用的技术，与业界在NER任务当中所使用的技术是一致的。

# 摘要

​	对于机器学习任务来说，数据和算法同等的重要，所以后面会主要分两部分来讲，先讲数据，再讲算法，也就是模型

​	在具体工作的过程中，我主要负责导航域上面的相关工作，所以后面的一些说明例子，也会主要集中在导航域上，其他的域上的内容，可以做相应的类推。



# 数据

​	在这部分，会主要介绍，数据准备，数据标注，特征工程，以及一些小tips。

### 数据准备

​	我们这里的训练数据主要是两部分

1. 众包数据：众包数据是我们团队根据我们的任务具体到细化的意图收集回来的用户QUERY
2. 用户数据：用户以前在使用过程中真实输入的语句，将导航相关的收集起来

### 数据标注

​	因为在我们的模型训练之前，并没有一份能够适用于我们现有业务的标注好的数据，所以我们需要根据我们的数据，自行对数据做相应的标注

#### 标注方式

​	这里的数据标注主要用BIO（*Begin*, *Intermediate*, *Other*）标注方式来做标注，下面举例说明：

- 字符粒度：导(O)航(O)到(O)天(B_POI)安(I_POI)门(I_POI)
- 分词粒度：找(O)一下(O)回家(B_HOME)的(O)路线(O)

​	至于具体使用哪种粒度，需要根据业务自行选择，各有相应一些优缺点

#### 标注方法

​	1.众包数据：可以认为是半结构化数据，数据中提供了句子中对应的POI信息，可以比较容易的通过脚本抽取然后对其做相应的标注，但是对于一些其他的属性，比如是否躲避拥堵则没有提供，这里需要重新标注，标注方法会在后面介绍。

​	2.用户数据：用户数据是完全不带标注信息的，我们要做的工作就是将用户query标注为我们需要的格式，下面将主要介绍一下在这里所做的工作

##### 匹配方式

​	对于序列数据标注，最常用的办法是使用**字符串最长匹配**，也就是找出在我们字典中能找到的最长的word。

​	如，对于一个query“我要去北京天安门”，在我们的字典中，同时匹配到“北京”、“天安门”、“北京天安门”等三个词，那么我们需要选择其中最长的那个，也就是“北京天安门”，我们最终会将其标注为以下的形式

```导(O)航(O)到(O)天(B_POI)安(I_POI)门(I_POI)
我(O)要(O)去(O)北(B_POI)京(I_POI)天(I_POI)安(I_POI)门(I_POI)
```

##### 匹配算法

​	这里就涉及到字符串多模匹配的问题了，也就是在一个字符串中，同时匹配在字典中的所有子串，在这里我们使用AC自动机算法（即：**Aho–Corasick**算法），这个算法在这里就不做详细介绍了，网上有大量的资料对此作了详细的说明，我们需要知道的是这个算法对于字符串多模匹配的任务来说，有近似线性的时间复杂度，效率很高就好了，这个算法的python实现在[这里](https://pypi.org/project/pyahocorasick/)。

##### 字典生成

​	OK，到这里，我们已经知道该怎么找到需要标记的子串了，那么有另外一个问题，字典在哪里来呢，到目前为止，我们并没有一个能够可用的字典，这里你可能会想，我可以在网上爬取，或者从公司内部，比如高德来拿到这样一个字典，不能说这样做不可以，只是可能会没那么快，另外即使拿到了可能也需要大量的工作对其进行处理才能使用，我们在这里用一个简单的办法，迅速的先生成了一批可用的高质量POI字典。

​	1. 选取用户query中的高频query，例如出现次数大于3的，说明不止一次使用过这种case，是偶发的badcase输入概率很低

​	2.找到其中的一些固定的模式，比如，导航到POI，我要去POI，找到这种模式的query，提取后面的POI，将其放到字典中。

​	3.根据这批种子的poi字典，通过上面的最长匹配的方法，标注一批数据，这样可以通过高频准确的字典，标记出其他低频的模式中的POI信息，然后用单机的[CRF++](<https://taku910.github.io/crfpp/>)，来训练一个单机的CRF模型，找到这个低频的模式，然后使用这个模型来对其他的不在模式内的句子进行识别，识别出其中的POI，这样我们又获得了一批POI，将其加入字典中，我们继续前面的过程，标注数据，训练模型，识别poi，加入词典，直到我们能够找出覆盖率高，准确率也较高的词典，然后我们在将此字典的基础上，对数据进行标注，用于后面的模型训练。

#### TIPS

这里在用脚本对query做标准的过程中，有几个注意的点，会增加对于数据标注的准确率，以及创造更多的适用于训练的数据集

A：对poi进行标注拼接，如“我要去北京天安门”，可能在字典中，前期只有北京，天安门两个poi，而没有北京，天安门，如果不做拼接，标注可能是这样的

```我(O)要(O)去(O)北(B_POI)京(I_POI)天(B_POI)安(I_POI)门(I_POI)
我(O)要(O)去(O)北(B_POI)京(I_POI)天(B_POI)安(I_POI)门(I_POI)
```

而拼接了之后应该是这样的,	这样是更准确的标注

```我(O)要(O)去(O)北(B_POI)京(I_POI)天(B_POI)安(I_POI)门(I_POI)
我(O)要(O)去(O)北(B_POI)京(I_POI)天(I_POI)安(I_POI)门(I_POI)
```

B：对于“美丽家园小区23号楼”这种POI，我们的词典中，可能只包含“美丽家园小区”，在这里我们需要对23号楼这种表述做相应的扩展，才能让标注有更加的准确，在这里主要是收集了一批后缀词，然后对于形式如（POI + 数字 + 后缀词）的这种组合，自动的对扩展后缀词

C：众包数据增强，众包数据整体句式形式多，质量较高，所以对众包数据做相应的增强，提高整体在训练数据集合中的比重，让模型找到众包的模式，增加的拟合能力，具体的做法就是将众包POI替换为字典中的POI，同时将众包的数据替换后的数据量增加，这样防止模型将POI识别为模式，通过替换不同的POI让模型更加泛化，适应能力更强

D：负例数据，负例数据主要来源于与当前模型不同的域，比如我现在训练的是导航域的模型，那么负例就是来自于音乐，广播等其他域的数据，将其他域的数据都标记为O，数据量与正例相当即可

### 特征工程

​	虽然说在深度学习时代，对于特征工程的工作来说，已经大为的简化了，甚至有人对此不屑一顾，但是从实际来看做好前面的工作对于任务来说仍然是一种提升模型效果非常有效的手段

​	1.数字,对于query中的数字，我这里会统一处理为一个标记符，如\$NUM\$，形式类似于\$UNK\$（代表未登录词汇）

​	2.对于英文统一处理为小写

​	3.分词，使用统一的分词方式对训练模型，以及线上的应用做分词，同时使用该分词方式做分词来生成预训练的词向量，而不是使用网络下载的其它分词方法生成的词向量。

​	4.预训练词向量，使用预训练的词向量可以快速提升模型的拟合能力，尤其在训练数据较少的情况下，使用预训练词向量是一个更好的选择，现在词向量的解决方案有很多，主要有glove、fasttext和word2vec几种，在实际的使用过程中，经评估，使用fasttext 略好与glove，二者效果明显好于word2vec，同时也好于在模型中自训练词向量（即不适用预训练词向量）（但是理论上当训练数据量足够大的情况下，此种方式可能更优）

# 模型

### 做NER主要模型方法

- 传统模型：隐马尔科夫模型(HMM)  ->  最大熵马尔科夫模型(MEMM)  ->  条件随机场(CRF)

- 神经网络：RNN/LSTM/CNN+CRF  ->    BiLSTM+CRF             ->            BiLSTM+CNN+CRF

传统模型我们在这里并不做具体的讨论，网络中有大量的资料可以了解学习

在我们的实际应用中，目前还没有用到BiLSTM+CNN+CRF，而是使用了业界最常用的BiLSTM+CRF神经网络结构





### 层次结构

#### 输入层

​	使用alinlp对输入query做分词，使用对应的预训练词向量作为词表示，同时在该词向量之后加入词性的one-hot表示，共同组成输入特征（batch_size，timestep, feature）

#### bi-LSTM（双向RNN）

​	bilstm是一种RNN的变体，被称为深度学习在自然语言处理任务的瑞士军刀，其通过在正序和倒序两个方向上对文本序列做相应的处理，同时捕获两个方向上的序列特征，然后将二者的表示合并在一起，从而捕获到单向RNN可能忽略的模式，将句子中每个词的特征转换为固定长度的隐层向量表达 (batch_size，timestep, lstm_output_feature_map)

#### CRF层

​	CRF层结合前面lstm层的输出，学习到lstm层输出到目标标注的结果的参数，由这些参数可以计算特征到任意标签的概率，通过这些概率，得到最优序列结果，最终将其映射为对应的标签。

### 神经网络结构图







![Pasted Graphic 1.pdf](/Users/fengliqiang/Library/Application Support/typora-user-images/54DAD904-1456-4E29-AB0E-24BE3BDC02DB/Pasted%20Graphic%201.pdf)





### 用keras实现一个BiLSTM+CRF的模型

​	Keras 是一个用 Python 编写的高级神经网络 API，它能够以 [TensorFlow](https://github.com/tensorflow/tensorflow), [CNTK](https://github.com/Microsoft/cntk), 或者 [Theano](https://github.com/Theano/Theano) 作为后端运行。Keras 的开发重点是支持快速的实验。能够以最小的时延把你的想法转换为实验结果，是做好研究的关键。

​	下面我们用Keras来根据以上的网络结构实现一个简单的模型。

```python
import keras
from keras import Sequential, layers
from keras_contrib.layers import CRF

model = Sequential()
#加入embedding层
model.add(layers.Embedding(len(vocabs), embedding_dim, mask_zero=True))
#BI-LSTM层，输出的大小为lstm_size，返回全部序列，而不是lstm的最后一个序列
model.add(layers.Bidirectional(layers.LSTM(lstm_size, return_sequences=True)))
#加一个crf层，注意CRF不在keras基础包中，需要包含keras_contrib
crf = CRF(len(tags), sparse_target=True)
model.add(crf)
model.summary()
#将embedding层设置为预训练词向量
model.layers[0].set_weights([embedding_matrix])
#将预训练词向量设置为不可训练，防止模型更新导致词向量偏差，效果变差
model.layers[0].trainable = False
#编译模型
model.compile('adam', loss=crf.loss_function, metrics=[crf.accuracy])
#在训练集上训练，在验证集上验证
model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=[x_valid, y_valid])
```

# 其他

#### 一些对效果有提升的改进点：

1.在word表示之前拼接一个char的bilstm训练的表示

2.加词性特征

#### 计划尝试改进的点

1.加入注意力机制（attention）

2.加入cnn层，对输入需要做卷积，捕获更多的局部信息

3.加入word positions, head positions信息

4.加入句法结构的dependency roles信息

#### 名词解释：

POI：Point of interesting，兴趣点，可以简单理解为位置信息